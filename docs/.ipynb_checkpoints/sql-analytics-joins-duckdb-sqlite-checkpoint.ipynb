
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# In-notebook SQL Analytics and Joins with DuckDB/SQLite\n",
    "\n",
    "In medical data integration, we often need to combine data from multiple sources such as patient records, laboratory results, and imaging data. SQL databases provide powerful tools for joining and analyzing these datasets efficiently. This notebook demonstrates how to use DuckDB and SQLite directly within Jupyter notebooks for medical data analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "First, let's install and import the necessary libraries for working with DuckDB and SQLite in our notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckdb sqlite3 pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Now we'll import the required libraries for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Let's create sample medical datasets that represent common scenarios in healthcare data integration. We'll create patient demographics, laboratory results, and medication records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample patient demographics\n",
    "np.random.seed(42)\n",
    "n_patients = 1000\n",
    "\n",
    "patients_df = pd.DataFrame({\n",
    "    'patient_id': range(1, n_patients + 1),\n",
    "    'age': np.random.randint(18, 90, n_patients),\n",
    "    'gender': np.random.choice(['M', 'F'], n_patients),\n",
    "    'admission_date': pd.date_range('2023-01-01', periods=n_patients, freq='6H'),\n",
    "    'diagnosis_code': np.random.choice(['I25.9', 'E11.9', 'J44.1', 'N18.6'], n_patients)\n",
    "})\n",
    "\n",
    "print(\"Sample patient data:\")\n",
    "patients_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Next, we'll generate laboratory results data with multiple test results per patient to simulate real clinical scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample laboratory results\n",
    "lab_tests = ['glucose', 'creatinine', 'hemoglobin', 'cholesterol']\n",
    "lab_data = []\n",
    "\n",
    "for patient_id in range(1, n_patients + 1):\n",
    "    # Each patient has 1-5 lab tests\n",
    "    n_tests = np.random.randint(1, 6)\n",
    "    selected_tests = np.random.choice(lab_tests, n_tests, replace=False)\n",
    "    \n",
    "    for test in selected_tests:\n",
    "        if test == 'glucose':\n",
    "            value = np.random.normal(100, 20)\n",
    "        elif test == 'creatinine':\n",
    "            value = np.random.normal(1.2, 0.3)\n",
    "        elif test == 'hemoglobin':\n",
    "            value = np.random.normal(13.5, 2.0)\n",
    "        else:  # cholesterol\n",
    "            value = np.random.normal(200, 40)\n",
    "        \n",
    "        lab_data.append({\n",
    "            'patient_id': patient_id,\n",
    "            'test_name': test,\n",
    "            'test_value': round(value, 2),\n",
    "            'test_date': patients_df.loc[patient_id-1, 'admission_date'] + timedelta(days=np.random.randint(0, 7))\n",
    "        })\n",
    "\n",
    "lab_results_df = pd.DataFrame(lab_data)\n",
    "print(f\"Generated {len(lab_results_df)} lab results\")\n",
    "lab_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Now let's create a medications dataset that we can later join with our patient and lab data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample medication data\n",
    "medications = ['metformin', 'lisinopril', 'atorvastatin', 'metoprolol', 'furosemide']\n",
    "med_data = []\n",
    "\n",
    "for patient_id in range(1, n_patients + 1):\n",
    "    # Each patient has 0-3 medications\n",
    "    n_meds = np.random.randint(0, 4)\n",
    "    if n_meds > 0:\n",
    "        selected_meds = np.random.choice(medications, n_meds, replace=False)\n",
    "        \n",
    "        for med in selected_meds:\n",
    "            med_data.append({\n",
    "                'patient_id': patient_id,\n",
    "                'medication_name': med,\n",
    "                'dosage_mg': np.random.choice([25, 50, 100, 200]),\n",
    "                'start_date': patients_df.loc[patient_id-1, 'admission_date']\n",
    "            })\n",
    "\n",
    "medications_df = pd.DataFrame(med_data)\n",
    "print(f\"Generated {len(medications_df)} medication records\")\n",
    "medications_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Working with DuckDB\n",
    "\n",
    "DuckDB is an excellent choice for analytical workloads and can work directly with pandas DataFrames. Let's establish a connection and load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DuckDB connection\n",
    "conn_duck = duckdb.connect(':memory:')\n",
    "print(\"DuckDB connection established\")\n",
    "print(f\"DuckDB version: {conn_duck.execute('SELECT version()').fetchone()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "We'll register our pandas DataFrames as tables in DuckDB, making them available for SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register pandas DataFrames as DuckDB tables\n",
    "conn_duck.register('patients', patients_df)\n",
    "conn_duck.register('lab_results', lab_results_df)\n",
    "conn_duck.register('medications', medications_df)\n",
    "\n",
    "print(\"Tables registered in DuckDB:\")\n",
    "tables = conn_duck.execute(\"SHOW TABLES\").fetchall()\n",
    "for table in tables:\n",
    "    print(f\"- {table[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Let's perform a basic query to understand our patient demographics using SQL aggregation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic demographic analysis\n",
    "demographic_query = \"\"\"\n",
    "SELECT \n",
    "    gender,\n",
    "    COUNT(*) as patient_count,\n",
    "    ROUND(AVG(age), 1) as avg_age,\n",
    "    MIN(age) as min_age,\n",
    "    MAX(age) as max_age\n",
    "FROM patients \n",
    "GROUP BY gender\n",
    "ORDER BY gender\n",
    "\"\"\"\n",
    "\n",
    "demographics_result = conn_duck.execute(demographic_query).df()\n",
    "print(\"Patient Demographics:\")\n",
    "demographics_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Now let's perform an inner join to combine patient data with their laboratory results, which is a common operation in medical data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join: patients with lab results\n",
    "join_query = \"\"\"\n",
    "SELECT \n",
    "    p.patient_id,\n",
    "    p.age,\n",
    "    p.gender,\n",
    "    p.diagnosis_code,\n",
    "    l.test_name,\n",
    "    l.test_value,\n",
    "    l.test_date\n",
    "FROM patients p\n",
    "INNER JOIN lab_results l ON p.patient_id = l.patient_id\n",
    "WHERE p.age > 65\n",
    "ORDER BY p.patient_id, l.test_name\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "elderly_labs = conn_duck.execute(join_query).df()\n",
    "print(\"Lab results for elderly patients (age > 65):\")\n",
    "elderly_labs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Let's perform a more complex analysis using a left join to find patients who may be missing certain lab tests, which is crucial for identifying gaps in care."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join to find patients with specific diagnosis but missing glucose tests\n",
    "missing_tests_query = \"\"\"\n",
    "SELECT \n",
    "    p.patient_id,\n",
    "    p.diagnosis_code,\n",
    "    p.age,\n",
    "    CASE WHEN l.test_name IS NULL THEN 'Missing glucose test' \n",
    "         ELSE 'Has glucose test' END as glucose_status\n",
    "FROM patients p\n",
    "LEFT JOIN (\n",
    "    SELECT DISTINCT patient_id, test_name \n",
    "    FROM lab_results \n",
    "    WHERE test_name = 'glucose'\n",
    ") l ON p.patient_id = l.patient_id\n",
    "WHERE p.diagnosis_code = 'E11.9'  -- Diabetes diagnosis\n",
    "ORDER BY glucose_status, p.patient_id\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "\n",
    "diabetes_glucose_check = conn_duck.execute(missing_tests_query).df()\n",
    "print(\"Diabetes patients and their glucose test status:\")\n",
    "diabetes_glucose_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Now let's perform a three-way join to get a comprehensive view of patients, their lab results, and medications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three-way join for comprehensive patient view\n",
    "comprehensive_query = \"\"\"\n",
    "SELECT \n",
    "    p.patient_id,\n",
    "    p.age,\n",
    "    p.diagnosis_code,\n",
    "    l.test_name,\n",
    "    l.test_value,\n",
    "    m.medication_name,\n",
    "    m.dosage_mg\n",
    "FROM patients p\n",
    "LEFT JOIN lab_results l ON p.patient_id = l.patient_id\n",
    "LEFT JOIN medications m ON p.patient_id = m.patient_id\n",
    "WHERE p.patient_id <= 10\n",
    "ORDER BY p.patient_id, l.test_name, m.medication_name\n",
    "\"\"\"\n",
    "\n",
    "comprehensive_view = conn_duck.execute(comprehensive_query).df()\n",
    "print(\"Comprehensive patient view (first 10 patients):\")\n",
    "comprehensive_view.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Let's calculate some clinical metrics using window functions to analyze glucose trends over time for diabetic patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window functions for glucose trend analysis\n",
    "glucose_trend_query = \"\"\"\n",
    "SELECT \n",
    "    p.patient_id,\n",
    "    p.diagnosis_code,\n",
    "    l.test_value as glucose_level,\n",
    "    l.test_date,\n",
    "    AVG(l.test_value) OVER (PARTITION BY p.patient_id) as avg_glucose,\n",
    "    ROW_NUMBER() OVER (PARTITION BY p.patient_id ORDER BY l.test_date) as test_sequence,\n",
    "    CASE \n",
    "        WHEN l.test_value > 140 THEN 'High'\n",
    "        WHEN l.test_value < 70 THEN 'Low'\n",
    "        ELSE 'Normal'\n",
    "    END as glucose_category\n",
    "FROM patients p\n",
    "INNER JOIN lab_results l ON p.patient_id = l.patient_id\n",
    "WHERE l.test_name = 'glucose' AND p.diagnosis_code = 'E11.9'\n",
    "ORDER BY p.patient_id, l.test_date\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "glucose_trends = conn_duck.execute(glucose_trend_query).df()\n",
    "print(\"Glucose trends for diabetic patients:\")\n",
    "glucose_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Working with SQLite\n",
    "\n",
    "Now let's demonstrate similar operations using SQLite, which is another popular embedded database option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQLite connection and tables\n",
    "conn_sqlite = sqlite3.connect(':memory:')\n",
    "\n",
    "# Load DataFrames into SQLite\n",
    "patients_df.to_sql('patients', conn_sqlite, if_exists='replace', index=False)\n",
    "lab_results_df.to_sql('lab_results', conn_sqlite, if_exists='replace', index=False)\n",
    "medications_df.to_sql('medications', conn_sqlite, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data loaded into SQLite\")\n",
    "print(f\"SQLite version: {sqlite3.sqlite_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Let's perform a similar join operation in SQLite to identify medication patterns by diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medication patterns by diagnosis in SQLite\n",
    "med_pattern_query = \"\"\"\n",
    "SELECT \n",
    "    p.diagnosis_code,\n",
    "    m.medication_name,\n",
    "    COUNT(*) as prescription_count,\n",
    "    ROUND(AVG(m.dosage_mg), 1) as avg_dosage\n",
    "FROM patients p\n",
    "INNER JOIN medications m ON p.patient_id = m.patient_id\n",
    "GROUP BY p.diagnosis_code, m.medication_name\n",
    "HAVING COUNT(*) >= 5\n",
    "ORDER BY p.diagnosis_code, prescription_count DESC\n",
    "\"\"\"\n",
    "\n",
    "med_patterns = pd.read_sql_query(med_pattern_query, conn_sqlite)\n",
    "print(\"Medication patterns by diagnosis (SQLite):\")\n",
    "med_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Let's create a summary report using SQLite that combines multiple metrics for clinical dashboard purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical summary report using SQLite\n",
    "summary_query = \"\"\"\n",
    "SELECT \n",
    "    p.diagnosis_code,\n",
    "    COUNT(DISTINCT p.patient_id) as total_patients,\n",
    "    ROUND(AVG(p.age), 1) as avg_age,\n",
    "    COUNT(DISTINCT l.patient_id) as patients_with_labs,\n",
    "    COUNT(DISTINCT m.patient_id) as patients_with_meds,\n",
    "    ROUND(\n",
    "        100.0 * COUNT(DISTINCT l.patient_id) / COUNT(DISTINCT p.patient_id), 1\n",
    "    ) as lab_coverage_pct\n",
    "FROM patients p\n",
    "LEFT JOIN lab_results l ON p.patient_id = l.patient_id\n",
    "LEFT JOIN medications m ON p.patient_id = m.patient_id\n",
    "GROUP BY p.diagnosis_code\n",
    "ORDER BY total_patients DESC\n",
    "\"\"\"\n",
    "\n",
    "clinical_summary = pd.read_sql_query(summary_query, conn_sqlite)\n",
    "print(\"Clinical Summary Report:\")\n",
    "clinical_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Visualization of Query Results\n",
    "\n",
    "Let's create some visualizations based on our SQL query results to demonstrate how database analytics integrate with data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Patient count by diagnosis\n",
    "ax1.bar(clinical_summary['diagnosis_code'], clinical_summary['total_patients'])\n",
    "ax1.set_title('Patient Count by Diagnosis')\n",
    "ax1.set_xlabel('Diagnosis Code')\n",
    "ax1.set_ylabel('Number of Patients')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Lab coverage by diagnosis\n",
    "ax2.bar(clinical_summary['diagnosis_code'], clinical_summary['lab_coverage_pct'], color='green', alpha=0.7)\n",
    "ax2.set_title('Lab Test Coverage by Diagnosis')\n",
    "ax2.set_xlabel('Diagnosis Code')\n",
    "ax2.set_ylabel('Coverage Percentage')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Age distribution by gender\n",
    "gender_age = conn_duck.execute(\"\"\"\n",
    "SELECT gender, age FROM patients\n",
    "\"\"\").df()\n",
    "\n",
    "for gender in ['M', 'F']:\n",
    "    ages = gender_age[gender_age['gender'] == gender]['age']\n",
    "    ax3.hist(ages, alpha=0.6, label=f'Gender {gender}', bins=20)\n",
    "ax3.set_title('Age Distribution by Gender')\n",
    "ax3.set_xlabel('Age')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Glucose levels distribution\n",
    "glucose_data = conn_duck.execute(\"\"\"\n",
    "SELECT test_value FROM lab_results WHERE test_name = 'glucose'\n",
    "\"\"\").df()\n",
    "\n",
    "ax4.hist(glucose_data['test_value'], bins=30, alpha=0.7, color='orange')\n",
    "ax4.axvline(x=100, color='red', linestyle='--', label='Normal level')\n",
    "ax4.set_title('Glucose Levels Distribution')\n",
    "ax4.set_xlabel('Glucose Level (mg/dL)')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Finally, let's clean up our database connections to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connections\n",
    "conn_duck.close()\n",
    "conn_sqlite.close()\n",
    "print(\"Database connections closed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **DuckDB** excels at analytical queries and works seamlessly with pandas DataFrames\n",
    "2. **SQLite** is excellent for persistent storage and standard SQL operations\n",
    "3. **Joins** are essential for integrating medical data from multiple sources\n",
    "4. **Window functions** help analyze trends and patterns in clinical data\n",
    "5. **Left joins** are crucial for identifying missing data or gaps in care\n",
    "6. SQL results can be easily visualized using standard Python plotting libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "**Clinical Data Integration Challenge**\n",
    "\n",
    "Using the techniques learned in this notebook, complete the following tasks:\n",
    "\n",
    "1. **Create a new dataset** for \"vital signs\" with patient_id, measurement_type (blood_pressure, heart_rate, temperature), measurement_value, and measurement_date\n",
    "\n",
    "2. **Write SQL queries** to:\n",
    "   - Find patients who have both high glucose levels (>140) AND are taking metformin\n",
    "   - Identify patients with heart disease diagnosis (I25.9) who are missing cholesterol tests\n",
    "   - Calculate the average number of different medication types per diagnosis\n",
    "\n",
    "3. **Perform a four-way join** between patients, lab_results, medications, and your new vital_signs table to create a comprehensive patient health summary\n",
    "\n",
    "4. **Create visualizations** showing:\n",
    "   - The relationship between age and number of medications\n",
    "   - Distribution of lab test completion rates by diagnosis\n",
    "\n",
    "5. **Compare performance** between DuckDB and SQLite for your most complex query and discuss which would be better for different use cases in medical data integration\n",
    "\n",
    "Document your findings and explain how these SQL techniques would be valuable in real-world medical data integration scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
